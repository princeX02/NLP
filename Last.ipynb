{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e850aba6-1fb9-4294-9ffa-df7a12a1277c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=\"\"\"I’m Prince Chaudhary, a 3rd-year CSE student focused on data science and algorithms.\n",
    "I optimize scheduling (SJF) and design efficient search strategies.\n",
    "I build image-processing tools in MATLAB and Python on my M3 Pro Mac.\n",
    "I’m passionate about open-source collaboration and machine-learning innovation.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2ac2daf-9429-4204-819e-b0ae4663c700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I’m Prince Chaudhary, a 3rd-year CSE student focused on data science and algorithms.\n",
      "I optimize scheduling (SJF) and design efficient search strategies.\n",
      "I build image-processing tools in MATLAB and Python on my M3 Pro Mac.\n",
      "I’m passionate about open-source collaboration and machine-learning innovation.\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c852515c-a815-49f9-a17b-a15c8ba5629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Tokenitization coverting corpus -- into doucuments\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bdc605a-de3d-4e0a-a2b3-3e9828fcdd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fec5b09-a227-4173-8a8d-17da16a57a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I’m Prince Chaudhary, a 3rd-year CSE student focused on data science and algorithms.',\n",
       " 'I optimize scheduling (SJF) and design efficient search strategies.',\n",
       " 'I build image-processing tools in MATLAB and Python on my M3 Pro Mac.',\n",
       " 'I’m passionate about open-source collaboration and machine-learning innovation.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3633e4c-fe82-4331-a726-0dce2656df4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9041e349-3081-4534-8e26-52f56228ac90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I’m Prince Chaudhary, a 3rd-year CSE student focused on data science and algorithms.\n",
      "I optimize scheduling (SJF) and design efficient search strategies.\n",
      "I build image-processing tools in MATLAB and Python on my M3 Pro Mac.\n",
      "I’m passionate about open-source collaboration and machine-learning innovation.\n"
     ]
    }
   ],
   "source": [
    "for sentencse in documents:\n",
    "    print(sentencse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d9857bf-bb82-4e56-8b91-91174f551343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d0c7cb3-1360-4d9c-86d1-13247b68817f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization converting paragraph -- paragraph into words\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8f1b96e-4c83-4f8c-b7c4-4493edc14fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " '’',\n",
       " 'm',\n",
       " 'Prince',\n",
       " 'Chaudhary',\n",
       " ',',\n",
       " 'a',\n",
       " '3rd-year',\n",
       " 'CSE',\n",
       " 'student',\n",
       " 'focused',\n",
       " 'on',\n",
       " 'data',\n",
       " 'science',\n",
       " 'and',\n",
       " 'algorithms',\n",
       " '.',\n",
       " 'I',\n",
       " 'optimize',\n",
       " 'scheduling',\n",
       " '(',\n",
       " 'SJF',\n",
       " ')',\n",
       " 'and',\n",
       " 'design',\n",
       " 'efficient',\n",
       " 'search',\n",
       " 'strategies',\n",
       " '.',\n",
       " 'I',\n",
       " 'build',\n",
       " 'image-processing',\n",
       " 'tools',\n",
       " 'in',\n",
       " 'MATLAB',\n",
       " 'and',\n",
       " 'Python',\n",
       " 'on',\n",
       " 'my',\n",
       " 'M3',\n",
       " 'Pro',\n",
       " 'Mac',\n",
       " '.',\n",
       " 'I',\n",
       " '’',\n",
       " 'm',\n",
       " 'passionate',\n",
       " 'about',\n",
       " 'open-source',\n",
       " 'collaboration',\n",
       " 'and',\n",
       " 'machine-learning',\n",
       " 'innovation',\n",
       " '.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "419e253b-013e-4272-b2b5-38b492bc6f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I']\n",
      "['’']\n",
      "['m']\n",
      "[]\n",
      "['P']\n",
      "['r']\n",
      "['i']\n",
      "['n']\n",
      "['c']\n",
      "['e']\n",
      "[]\n",
      "['C']\n",
      "['h']\n",
      "['a']\n",
      "['u']\n",
      "['d']\n",
      "['h']\n",
      "['a']\n",
      "['r']\n",
      "['y']\n",
      "[',']\n",
      "[]\n",
      "['a']\n",
      "[]\n",
      "['3']\n",
      "['r']\n",
      "['d']\n",
      "['-']\n",
      "['y']\n",
      "['e']\n",
      "['a']\n",
      "['r']\n",
      "[]\n",
      "['C']\n",
      "['S']\n",
      "['E']\n",
      "[]\n",
      "['s']\n",
      "['t']\n",
      "['u']\n",
      "['d']\n",
      "['e']\n",
      "['n']\n",
      "['t']\n",
      "[]\n",
      "['f']\n",
      "['o']\n",
      "['c']\n",
      "['u']\n",
      "['s']\n",
      "['e']\n",
      "['d']\n",
      "[]\n",
      "['o']\n",
      "['n']\n",
      "[]\n",
      "['d']\n",
      "['a']\n",
      "['t']\n",
      "['a']\n",
      "[]\n",
      "['s']\n",
      "['c']\n",
      "['i']\n",
      "['e']\n",
      "['n']\n",
      "['c']\n",
      "['e']\n",
      "[]\n",
      "['a']\n",
      "['n']\n",
      "['d']\n",
      "[]\n",
      "['a']\n",
      "['l']\n",
      "['g']\n",
      "['o']\n",
      "['r']\n",
      "['i']\n",
      "['t']\n",
      "['h']\n",
      "['m']\n",
      "['s']\n",
      "['.']\n",
      "[]\n",
      "['I']\n",
      "[]\n",
      "['o']\n",
      "['p']\n",
      "['t']\n",
      "['i']\n",
      "['m']\n",
      "['i']\n",
      "['z']\n",
      "['e']\n",
      "[]\n",
      "['s']\n",
      "['c']\n",
      "['h']\n",
      "['e']\n",
      "['d']\n",
      "['u']\n",
      "['l']\n",
      "['i']\n",
      "['n']\n",
      "['g']\n",
      "[]\n",
      "['(']\n",
      "['S']\n",
      "['J']\n",
      "['F']\n",
      "[')']\n",
      "[]\n",
      "['a']\n",
      "['n']\n",
      "['d']\n",
      "[]\n",
      "['d']\n",
      "['e']\n",
      "['s']\n",
      "['i']\n",
      "['g']\n",
      "['n']\n",
      "[]\n",
      "['e']\n",
      "['f']\n",
      "['f']\n",
      "['i']\n",
      "['c']\n",
      "['i']\n",
      "['e']\n",
      "['n']\n",
      "['t']\n",
      "[]\n",
      "['s']\n",
      "['e']\n",
      "['a']\n",
      "['r']\n",
      "['c']\n",
      "['h']\n",
      "[]\n",
      "['s']\n",
      "['t']\n",
      "['r']\n",
      "['a']\n",
      "['t']\n",
      "['e']\n",
      "['g']\n",
      "['i']\n",
      "['e']\n",
      "['s']\n",
      "['.']\n",
      "[]\n",
      "['I']\n",
      "[]\n",
      "['b']\n",
      "['u']\n",
      "['i']\n",
      "['l']\n",
      "['d']\n",
      "[]\n",
      "['i']\n",
      "['m']\n",
      "['a']\n",
      "['g']\n",
      "['e']\n",
      "['-']\n",
      "['p']\n",
      "['r']\n",
      "['o']\n",
      "['c']\n",
      "['e']\n",
      "['s']\n",
      "['s']\n",
      "['i']\n",
      "['n']\n",
      "['g']\n",
      "[]\n",
      "['t']\n",
      "['o']\n",
      "['o']\n",
      "['l']\n",
      "['s']\n",
      "[]\n",
      "['i']\n",
      "['n']\n",
      "[]\n",
      "['M']\n",
      "['A']\n",
      "['T']\n",
      "['L']\n",
      "['A']\n",
      "['B']\n",
      "[]\n",
      "['a']\n",
      "['n']\n",
      "['d']\n",
      "[]\n",
      "['P']\n",
      "['y']\n",
      "['t']\n",
      "['h']\n",
      "['o']\n",
      "['n']\n",
      "[]\n",
      "['o']\n",
      "['n']\n",
      "[]\n",
      "['m']\n",
      "['y']\n",
      "[]\n",
      "['M']\n",
      "['3']\n",
      "[]\n",
      "['P']\n",
      "['r']\n",
      "['o']\n",
      "[]\n",
      "['M']\n",
      "['a']\n",
      "['c']\n",
      "['.']\n",
      "[]\n",
      "['I']\n",
      "['’']\n",
      "['m']\n",
      "[]\n",
      "['p']\n",
      "['a']\n",
      "['s']\n",
      "['s']\n",
      "['i']\n",
      "['o']\n",
      "['n']\n",
      "['a']\n",
      "['t']\n",
      "['e']\n",
      "[]\n",
      "['a']\n",
      "['b']\n",
      "['o']\n",
      "['u']\n",
      "['t']\n",
      "[]\n",
      "['o']\n",
      "['p']\n",
      "['e']\n",
      "['n']\n",
      "['-']\n",
      "['s']\n",
      "['o']\n",
      "['u']\n",
      "['r']\n",
      "['c']\n",
      "['e']\n",
      "[]\n",
      "['c']\n",
      "['o']\n",
      "['l']\n",
      "['l']\n",
      "['a']\n",
      "['b']\n",
      "['o']\n",
      "['r']\n",
      "['a']\n",
      "['t']\n",
      "['i']\n",
      "['o']\n",
      "['n']\n",
      "[]\n",
      "['a']\n",
      "['n']\n",
      "['d']\n",
      "[]\n",
      "['m']\n",
      "['a']\n",
      "['c']\n",
      "['h']\n",
      "['i']\n",
      "['n']\n",
      "['e']\n",
      "['-']\n",
      "['l']\n",
      "['e']\n",
      "['a']\n",
      "['r']\n",
      "['n']\n",
      "['i']\n",
      "['n']\n",
      "['g']\n",
      "[]\n",
      "['i']\n",
      "['n']\n",
      "['n']\n",
      "['o']\n",
      "['v']\n",
      "['a']\n",
      "['t']\n",
      "['i']\n",
      "['o']\n",
      "['n']\n",
      "['.']\n"
     ]
    }
   ],
   "source": [
    "#Tokenization coverting documents -- into words\n",
    "from nltk.tokenize import sent_tokenize\n",
    "for documents in corpus:\n",
    "    print(sent_tokenize(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4fc375ff-58cb-405c-80a6-7aac51fbeeca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " '’',\n",
       " 'm',\n",
       " 'Prince',\n",
       " 'Chaudhary',\n",
       " ',',\n",
       " 'a',\n",
       " '3rd',\n",
       " '-',\n",
       " 'year',\n",
       " 'CSE',\n",
       " 'student',\n",
       " 'focused',\n",
       " 'on',\n",
       " 'data',\n",
       " 'science',\n",
       " 'and',\n",
       " 'algorithms',\n",
       " '.',\n",
       " 'I',\n",
       " 'optimize',\n",
       " 'scheduling',\n",
       " '(',\n",
       " 'SJF',\n",
       " ')',\n",
       " 'and',\n",
       " 'design',\n",
       " 'efficient',\n",
       " 'search',\n",
       " 'strategies',\n",
       " '.',\n",
       " 'I',\n",
       " 'build',\n",
       " 'image',\n",
       " '-',\n",
       " 'processing',\n",
       " 'tools',\n",
       " 'in',\n",
       " 'MATLAB',\n",
       " 'and',\n",
       " 'Python',\n",
       " 'on',\n",
       " 'my',\n",
       " 'M3',\n",
       " 'Pro',\n",
       " 'Mac',\n",
       " '.',\n",
       " 'I',\n",
       " '’',\n",
       " 'm',\n",
       " 'passionate',\n",
       " 'about',\n",
       " 'open',\n",
       " '-',\n",
       " 'source',\n",
       " 'collaboration',\n",
       " 'and',\n",
       " 'machine',\n",
       " '-',\n",
       " 'learning',\n",
       " 'innovation',\n",
       " '.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n",
    "wordpunct_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4cd9823b-b8c1-4d01-88cb-440251a068f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39f37443-6677-4772-97d7-5d838fce71ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " '’',\n",
       " 'm',\n",
       " 'Prince',\n",
       " 'Chaudhary',\n",
       " ',',\n",
       " 'a',\n",
       " '3rd',\n",
       " '-',\n",
       " 'year',\n",
       " 'CSE',\n",
       " 'student',\n",
       " 'focused',\n",
       " 'on',\n",
       " 'data',\n",
       " 'science',\n",
       " 'and',\n",
       " 'algorithms',\n",
       " '.',\n",
       " 'I',\n",
       " 'optimize',\n",
       " 'scheduling',\n",
       " '(',\n",
       " 'SJF',\n",
       " ')',\n",
       " 'and',\n",
       " 'design',\n",
       " 'efficient',\n",
       " 'search',\n",
       " 'strategies',\n",
       " '.',\n",
       " 'I',\n",
       " 'build',\n",
       " 'image',\n",
       " '-',\n",
       " 'processing',\n",
       " 'tools',\n",
       " 'in',\n",
       " 'MATLAB',\n",
       " 'and',\n",
       " 'Python',\n",
       " 'on',\n",
       " 'my',\n",
       " 'M3',\n",
       " 'Pro',\n",
       " 'Mac',\n",
       " '.',\n",
       " 'I',\n",
       " '’',\n",
       " 'm',\n",
       " 'passionate',\n",
       " 'about',\n",
       " 'open',\n",
       " '-',\n",
       " 'source',\n",
       " 'collaboration',\n",
       " 'and',\n",
       " 'machine',\n",
       " '-',\n",
       " 'learning',\n",
       " 'innovation',\n",
       " '.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n",
    "wordpunct_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56493a96-7489-4b1c-ae4e-52cc0b946066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " '’',\n",
       " 'm',\n",
       " 'Prince',\n",
       " 'Chaudhary',\n",
       " ',',\n",
       " 'a',\n",
       " '3rd',\n",
       " '-',\n",
       " 'year',\n",
       " 'CSE',\n",
       " 'student',\n",
       " 'focused',\n",
       " 'on',\n",
       " 'data',\n",
       " 'science',\n",
       " 'and',\n",
       " 'algorithms',\n",
       " '.',\n",
       " 'I',\n",
       " 'optimize',\n",
       " 'scheduling',\n",
       " '(',\n",
       " 'SJF',\n",
       " ')',\n",
       " 'and',\n",
       " 'design',\n",
       " 'efficient',\n",
       " 'search',\n",
       " 'strategies',\n",
       " '.',\n",
       " 'I',\n",
       " 'build',\n",
       " 'image',\n",
       " '-',\n",
       " 'processing',\n",
       " 'tools',\n",
       " 'in',\n",
       " 'MATLAB',\n",
       " 'and',\n",
       " 'Python',\n",
       " 'on',\n",
       " 'my',\n",
       " 'M3',\n",
       " 'Pro',\n",
       " 'Mac',\n",
       " '.',\n",
       " 'I',\n",
       " '’',\n",
       " 'm',\n",
       " 'passionate',\n",
       " 'about',\n",
       " 'open',\n",
       " '-',\n",
       " 'source',\n",
       " 'collaboration',\n",
       " 'and',\n",
       " 'machine',\n",
       " '-',\n",
       " 'learning',\n",
       " 'innovation',\n",
       " '.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n",
    "wordpunct_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca3affdc-bf94-4596-8c9f-d8e5076c8c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " '’',\n",
       " 'm',\n",
       " 'Prince',\n",
       " 'Chaudhary',\n",
       " ',',\n",
       " 'a',\n",
       " '3rd',\n",
       " '-',\n",
       " 'year',\n",
       " 'CSE',\n",
       " 'student',\n",
       " 'focused',\n",
       " 'on',\n",
       " 'data',\n",
       " 'science',\n",
       " 'and',\n",
       " 'algorithms',\n",
       " '.',\n",
       " 'I',\n",
       " 'optimize',\n",
       " 'scheduling',\n",
       " '(',\n",
       " 'SJF',\n",
       " ')',\n",
       " 'and',\n",
       " 'design',\n",
       " 'efficient',\n",
       " 'search',\n",
       " 'strategies',\n",
       " '.',\n",
       " 'I',\n",
       " 'build',\n",
       " 'image',\n",
       " '-',\n",
       " 'processing',\n",
       " 'tools',\n",
       " 'in',\n",
       " 'MATLAB',\n",
       " 'and',\n",
       " 'Python',\n",
       " 'on',\n",
       " 'my',\n",
       " 'M3',\n",
       " 'Pro',\n",
       " 'Mac',\n",
       " '.',\n",
       " 'I',\n",
       " '’',\n",
       " 'm',\n",
       " 'passionate',\n",
       " 'about',\n",
       " 'open',\n",
       " '-',\n",
       " 'source',\n",
       " 'collaboration',\n",
       " 'and',\n",
       " 'machine',\n",
       " '-',\n",
       " 'learning',\n",
       " 'innovation',\n",
       " '.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n",
    "wordpunct_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3546dcd6-1799-42e5-9a32-fec6a931ba94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "967a6412-620f-42f1-af09-712aaeebd845",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc72b76e-49e9-4536-80a7-af87c41f4cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I’m',\n",
       " 'Prince',\n",
       " 'Chaudhary',\n",
       " ',',\n",
       " 'a',\n",
       " '3rd-year',\n",
       " 'CSE',\n",
       " 'student',\n",
       " 'focused',\n",
       " 'on',\n",
       " 'data',\n",
       " 'science',\n",
       " 'and',\n",
       " 'algorithms.',\n",
       " 'I',\n",
       " 'optimize',\n",
       " 'scheduling',\n",
       " '(',\n",
       " 'SJF',\n",
       " ')',\n",
       " 'and',\n",
       " 'design',\n",
       " 'efficient',\n",
       " 'search',\n",
       " 'strategies.',\n",
       " 'I',\n",
       " 'build',\n",
       " 'image-processing',\n",
       " 'tools',\n",
       " 'in',\n",
       " 'MATLAB',\n",
       " 'and',\n",
       " 'Python',\n",
       " 'on',\n",
       " 'my',\n",
       " 'M3',\n",
       " 'Pro',\n",
       " 'Mac.',\n",
       " 'I’m',\n",
       " 'passionate',\n",
       " 'about',\n",
       " 'open-source',\n",
       " 'collaboration',\n",
       " 'and',\n",
       " 'machine-learning',\n",
       " 'innovation',\n",
       " '.']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991d425e-055c-403f-8e9e-2dc121608807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a126d5-3ed6-48b0-9aa7-2528b7657cad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f609c158-dd5b-4497-864e-cfef75c2a4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming of words using PorterStemmer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fcd7cc7a-6abb-423b-923f-b5cd83274cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df8761b4-5c99-4e64-85e2-7646f9ef99b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"eating\", \"eaten\", \"sleeps\", \"sleeping\", \"sleepless\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "69f20244-3c39-4466-a8e0-5a741aa81dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating ---> eat\n",
      "eaten ---> eaten\n",
      "sleeps ---> sleep\n",
      "sleeping ---> sleep\n",
      "sleepless ---> sleepless\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + \" ---> \" + stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f0dce467-6451-4b5f-ae47-a1804f4cb61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_words = [\n",
    "    \"history\",\n",
    "    \"historical\",\n",
    "    \"histories\",\n",
    "    \"historian\",\n",
    "    \"historians\",\n",
    "    \"historiography\",\n",
    "    \"historically\",\n",
    "    \"historic\",\n",
    "    \"historicity\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8fdc2d85-7b87-44c2-8985-4e77e950db93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history--> histori\n",
      "historical--> histor\n",
      "histories--> histori\n",
      "historian--> historian\n",
      "historians--> historian\n",
      "historiography--> historiographi\n",
      "historically--> histor\n",
      "historic--> histor\n",
      "historicity--> histor\n"
     ]
    }
   ],
   "source": [
    "for word in history_words:\n",
    "    print(word + \"--> \"+ stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d35267dd-614f-459c-971b-e4006f8a7fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming of wrods using RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0a9ea944-ec06-4554-ba57-95aac7a3d434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8664fc7f-0e46-4c57-85ee-87f625bb32f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Meaning of this the last words coananint the letter like {ing,s,e,able} will removed\n",
    "reg_stmmer=RegexpStemmer('ing$|s$|e$|able$|', min=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ea212376-7597-4ef2-b534-8e8abf49e684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stmmer.stem('eating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "54e6849c-ea9f-4de8-9b5d-290680d93290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'history'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a8d09c73-a0cb-48a8-a2fa-c547bad41be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming of wrods using RegexpStemmer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3739739c-bdc0-4ea4-9fa0-b349700d7666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "60385f34-085e-4873-a633-f41ba772cb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowball=SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bb5a34da-795c-4e0e-9b7f-160b74ffca74",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"eating\", \"eaten\", \"sleeps\", \"sleeping\", \"sleepless\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "24d07522-19c1-4d39-a3c9-2e46a4494fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating---> eat\n",
      "eaten---> eaten\n",
      "sleeps---> sleep\n",
      "sleeping---> sleep\n",
      "sleepless---> sleepless\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + \"---> \" + snowball.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "68fc01d4-9d6b-4c53-a09d-7a1bab99707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1b5b8c47-b04a-41e7-b232-4c5df9062f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1143f964-0994-44b5-ab9c-e4e175c7d97e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'history'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b8db1cdc-1a98-4d21-862d-9e3cf883f1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'historical'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"historical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3d8e9924-d966-4de6-bb88-f44485b5a07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Noune -- n it will treat the words as a noune\n",
    "# Verb --v it will treat the words as a vectors\n",
    "lemmatizer.lemmatize('going',pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "51247b79-352b-4adf-b27d-c61e5fab830b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'going'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('going',pos='n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "da876de2-3b86-4d6e-8012-849a6258ddcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"eating\", \"eaten\", \"sleeps\", \"sleeping\", \"sleepless\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bce88f11-1559-45dc-a6b3-1839680fb07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating--> eating\n",
      "eaten--> eaten\n",
      "sleeps--> sleep\n",
      "sleeping--> sleeping\n",
      "sleepless--> sleepless\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + \"--> \"+ lemmatizer.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21640e62-e43f-4a48-b896-d1eeba422fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopWords --> some of the word does not play important in \n",
    "#text for APJ Kalam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8c8be2d0-3846-4c1a-bf70-404cb2d87dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=\"\"\"Avul Pakir Jainulabdeen Abdul Kalam (/ˈəbdʊl kəˈlɑːm/ ⓘ; 15 October 1931 – 27 July 2015) was an Indian aerospace scientist and statesman who served as the president of India from 2002 to 2007.\n",
    "\n",
    "Born and raised in a Muslim family in Rameswaram, Tamil Nadu, Kalam studied physics and aerospace engineering. He spent the next four decades as a scientist and science administrator, mainly at the Defence Research and Development Organisation (DRDO) and Indian Space Research Organisation (ISRO) and was intimately involved in India's civilian space programme and military missile development efforts. He was known as the \"Missile Man of India\" for his work on the development of ballistic missile and launch vehicle technology. He also played a pivotal organisational, technical, and political role in Pokhran-II nuclear tests in 1998, India's second such test after the first test in 1974.\n",
    "\n",
    "Kalam was elected as the president of India in 2002 with the support of both the ruling Bharatiya Janata Party and the then-opposition Indian National Congress. He was widely referred to as the \"People's President\". He engaged in teaching, writing and public service after his presidency. He was a recipient of several awards, including the Bharat Ratna, India's highest civilian honour.\n",
    "\n",
    "While delivering a lecture at IIM Shillong, Kalam collapsed and died from an apparent cardiac arrest on 27 July 2015, aged 83. Thousands attended the funeral ceremony held in his hometown of Rameswaram, where he was buried with full state honours. A memorial was inaugurated near his home town in 2017.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "24aafc3d-7ecb-46a9-9664-0418d3cdafd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Avul Pakir Jainulabdeen Abdul Kalam (/ˈəbdʊl kəˈlɑːm/ ⓘ; 15 October 1931 – 27 July 2015) was an Indian aerospace scientist and statesman who served as the president of India from 2002 to 2007.\\n\\nBorn and raised in a Muslim family in Rameswaram, Tamil Nadu, Kalam studied physics and aerospace engineering. He spent the next four decades as a scientist and science administrator, mainly at the Defence Research and Development Organisation (DRDO) and Indian Space Research Organisation (ISRO) and was intimately involved in India\\'s civilian space programme and military missile development efforts. He was known as the \"Missile Man of India\" for his work on the development of ballistic missile and launch vehicle technology. He also played a pivotal organisational, technical, and political role in Pokhran-II nuclear tests in 1998, India\\'s second such test after the first test in 1974.\\n\\nKalam was elected as the president of India in 2002 with the support of both the ruling Bharatiya Janata Party and the then-opposition Indian National Congress. He was widely referred to as the \"People\\'s President\". He engaged in teaching, writing and public service after his presidency. He was a recipient of several awards, including the Bharat Ratna, India\\'s highest civilian honour.\\n\\nWhile delivering a lecture at IIM Shillong, Kalam collapsed and died from an apparent cardiac arrest on 27 July 2015, aged 83. Thousands attended the funeral ceremony held in his hometown of Rameswaram, where he was buried with full state honours. A memorial was inaugurated near his home town in 2017.'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3af88e89-21d2-40f5-9a0e-26a1bfe8b1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d86b78bc-54e2-4bde-b8cd-c40bbb4c0632",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "463bdc65-8048-4f74-9ed8-c5990311d6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/princechaudhary/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87780ed6-4943-4847-94ad-db46b8e810a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763302dd-29db-4c43-ba55-9498fbe8780c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ff106d84-80e8-4d9c-b538-3e7602339f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This are the stop words that are present in the english dictonary\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d06673-2e7b-482d-88a1-6fe4b4dcc026",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588081c4-826b-404c-b2c0-dcb4a5bce405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3092a285-a55d-43b9-9506-e9d316aa96cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['إذ',\n",
       " 'إذا',\n",
       " 'إذما',\n",
       " 'إذن',\n",
       " 'أف',\n",
       " 'أقل',\n",
       " 'أكثر',\n",
       " 'ألا',\n",
       " 'إلا',\n",
       " 'التي',\n",
       " 'الذي',\n",
       " 'الذين',\n",
       " 'اللاتي',\n",
       " 'اللائي',\n",
       " 'اللتان',\n",
       " 'اللتيا',\n",
       " 'اللتين',\n",
       " 'اللذان',\n",
       " 'اللذين',\n",
       " 'اللواتي',\n",
       " 'إلى',\n",
       " 'إليك',\n",
       " 'إليكم',\n",
       " 'إليكما',\n",
       " 'إليكن',\n",
       " 'أم',\n",
       " 'أما',\n",
       " 'أما',\n",
       " 'إما',\n",
       " 'أن',\n",
       " 'إن',\n",
       " 'إنا',\n",
       " 'أنا',\n",
       " 'أنت',\n",
       " 'أنتم',\n",
       " 'أنتما',\n",
       " 'أنتن',\n",
       " 'إنما',\n",
       " 'إنه',\n",
       " 'أنى',\n",
       " 'أنى',\n",
       " 'آه',\n",
       " 'آها',\n",
       " 'أو',\n",
       " 'أولاء',\n",
       " 'أولئك',\n",
       " 'أوه',\n",
       " 'آي',\n",
       " 'أي',\n",
       " 'أيها',\n",
       " 'إي',\n",
       " 'أين',\n",
       " 'أين',\n",
       " 'أينما',\n",
       " 'إيه',\n",
       " 'بخ',\n",
       " 'بس',\n",
       " 'بعد',\n",
       " 'بعض',\n",
       " 'بك',\n",
       " 'بكم',\n",
       " 'بكم',\n",
       " 'بكما',\n",
       " 'بكن',\n",
       " 'بل',\n",
       " 'بلى',\n",
       " 'بما',\n",
       " 'بماذا',\n",
       " 'بمن',\n",
       " 'بنا',\n",
       " 'به',\n",
       " 'بها',\n",
       " 'بهم',\n",
       " 'بهما',\n",
       " 'بهن',\n",
       " 'بي',\n",
       " 'بين',\n",
       " 'بيد',\n",
       " 'تلك',\n",
       " 'تلكم',\n",
       " 'تلكما',\n",
       " 'ته',\n",
       " 'تي',\n",
       " 'تين',\n",
       " 'تينك',\n",
       " 'ثم',\n",
       " 'ثمة',\n",
       " 'حاشا',\n",
       " 'حبذا',\n",
       " 'حتى',\n",
       " 'حيث',\n",
       " 'حيثما',\n",
       " 'حين',\n",
       " 'خلا',\n",
       " 'دون',\n",
       " 'ذا',\n",
       " 'ذات',\n",
       " 'ذاك',\n",
       " 'ذان',\n",
       " 'ذانك',\n",
       " 'ذلك',\n",
       " 'ذلكم',\n",
       " 'ذلكما',\n",
       " 'ذلكن',\n",
       " 'ذه',\n",
       " 'ذو',\n",
       " 'ذوا',\n",
       " 'ذواتا',\n",
       " 'ذواتي',\n",
       " 'ذي',\n",
       " 'ذين',\n",
       " 'ذينك',\n",
       " 'ريث',\n",
       " 'سوف',\n",
       " 'سوى',\n",
       " 'شتان',\n",
       " 'عدا',\n",
       " 'عسى',\n",
       " 'عل',\n",
       " 'على',\n",
       " 'عليك',\n",
       " 'عليه',\n",
       " 'عما',\n",
       " 'عن',\n",
       " 'عند',\n",
       " 'غير',\n",
       " 'فإذا',\n",
       " 'فإن',\n",
       " 'فلا',\n",
       " 'فمن',\n",
       " 'في',\n",
       " 'فيم',\n",
       " 'فيما',\n",
       " 'فيه',\n",
       " 'فيها',\n",
       " 'قد',\n",
       " 'كأن',\n",
       " 'كأنما',\n",
       " 'كأي',\n",
       " 'كأين',\n",
       " 'كذا',\n",
       " 'كذلك',\n",
       " 'كل',\n",
       " 'كلا',\n",
       " 'كلاهما',\n",
       " 'كلتا',\n",
       " 'كلما',\n",
       " 'كليكما',\n",
       " 'كليهما',\n",
       " 'كم',\n",
       " 'كم',\n",
       " 'كما',\n",
       " 'كي',\n",
       " 'كيت',\n",
       " 'كيف',\n",
       " 'كيفما',\n",
       " 'لا',\n",
       " 'لاسيما',\n",
       " 'لدى',\n",
       " 'لست',\n",
       " 'لستم',\n",
       " 'لستما',\n",
       " 'لستن',\n",
       " 'لسن',\n",
       " 'لسنا',\n",
       " 'لعل',\n",
       " 'لك',\n",
       " 'لكم',\n",
       " 'لكما',\n",
       " 'لكن',\n",
       " 'لكنما',\n",
       " 'لكي',\n",
       " 'لكيلا',\n",
       " 'لم',\n",
       " 'لما',\n",
       " 'لن',\n",
       " 'لنا',\n",
       " 'له',\n",
       " 'لها',\n",
       " 'لهم',\n",
       " 'لهما',\n",
       " 'لهن',\n",
       " 'لو',\n",
       " 'لولا',\n",
       " 'لوما',\n",
       " 'لي',\n",
       " 'لئن',\n",
       " 'ليت',\n",
       " 'ليس',\n",
       " 'ليسا',\n",
       " 'ليست',\n",
       " 'ليستا',\n",
       " 'ليسوا',\n",
       " 'ما',\n",
       " 'ماذا',\n",
       " 'متى',\n",
       " 'مذ',\n",
       " 'مع',\n",
       " 'مما',\n",
       " 'ممن',\n",
       " 'من',\n",
       " 'منه',\n",
       " 'منها',\n",
       " 'منذ',\n",
       " 'مه',\n",
       " 'مهما',\n",
       " 'نحن',\n",
       " 'نحو',\n",
       " 'نعم',\n",
       " 'ها',\n",
       " 'هاتان',\n",
       " 'هاته',\n",
       " 'هاتي',\n",
       " 'هاتين',\n",
       " 'هاك',\n",
       " 'هاهنا',\n",
       " 'هذا',\n",
       " 'هذان',\n",
       " 'هذه',\n",
       " 'هذي',\n",
       " 'هذين',\n",
       " 'هكذا',\n",
       " 'هل',\n",
       " 'هلا',\n",
       " 'هم',\n",
       " 'هما',\n",
       " 'هن',\n",
       " 'هنا',\n",
       " 'هناك',\n",
       " 'هنالك',\n",
       " 'هو',\n",
       " 'هؤلاء',\n",
       " 'هي',\n",
       " 'هيا',\n",
       " 'هيت',\n",
       " 'هيهات',\n",
       " 'والذي',\n",
       " 'والذين',\n",
       " 'وإذ',\n",
       " 'وإذا',\n",
       " 'وإن',\n",
       " 'ولا',\n",
       " 'ولكن',\n",
       " 'ولو',\n",
       " 'وما',\n",
       " 'ومن',\n",
       " 'وهو',\n",
       " 'يا',\n",
       " 'أبٌ',\n",
       " 'أخٌ',\n",
       " 'حمٌ',\n",
       " 'فو',\n",
       " 'أنتِ',\n",
       " 'يناير',\n",
       " 'فبراير',\n",
       " 'مارس',\n",
       " 'أبريل',\n",
       " 'مايو',\n",
       " 'يونيو',\n",
       " 'يوليو',\n",
       " 'أغسطس',\n",
       " 'سبتمبر',\n",
       " 'أكتوبر',\n",
       " 'نوفمبر',\n",
       " 'ديسمبر',\n",
       " 'جانفي',\n",
       " 'فيفري',\n",
       " 'مارس',\n",
       " 'أفريل',\n",
       " 'ماي',\n",
       " 'جوان',\n",
       " 'جويلية',\n",
       " 'أوت',\n",
       " 'كانون',\n",
       " 'شباط',\n",
       " 'آذار',\n",
       " 'نيسان',\n",
       " 'أيار',\n",
       " 'حزيران',\n",
       " 'تموز',\n",
       " 'آب',\n",
       " 'أيلول',\n",
       " 'تشرين',\n",
       " 'دولار',\n",
       " 'دينار',\n",
       " 'ريال',\n",
       " 'درهم',\n",
       " 'ليرة',\n",
       " 'جنيه',\n",
       " 'قرش',\n",
       " 'مليم',\n",
       " 'فلس',\n",
       " 'هللة',\n",
       " 'سنتيم',\n",
       " 'يورو',\n",
       " 'ين',\n",
       " 'يوان',\n",
       " 'شيكل',\n",
       " 'واحد',\n",
       " 'اثنان',\n",
       " 'ثلاثة',\n",
       " 'أربعة',\n",
       " 'خمسة',\n",
       " 'ستة',\n",
       " 'سبعة',\n",
       " 'ثمانية',\n",
       " 'تسعة',\n",
       " 'عشرة',\n",
       " 'أحد',\n",
       " 'اثنا',\n",
       " 'اثني',\n",
       " 'إحدى',\n",
       " 'ثلاث',\n",
       " 'أربع',\n",
       " 'خمس',\n",
       " 'ست',\n",
       " 'سبع',\n",
       " 'ثماني',\n",
       " 'تسع',\n",
       " 'عشر',\n",
       " 'ثمان',\n",
       " 'سبت',\n",
       " 'أحد',\n",
       " 'اثنين',\n",
       " 'ثلاثاء',\n",
       " 'أربعاء',\n",
       " 'خميس',\n",
       " 'جمعة',\n",
       " 'أول',\n",
       " 'ثان',\n",
       " 'ثاني',\n",
       " 'ثالث',\n",
       " 'رابع',\n",
       " 'خامس',\n",
       " 'سادس',\n",
       " 'سابع',\n",
       " 'ثامن',\n",
       " 'تاسع',\n",
       " 'عاشر',\n",
       " 'حادي',\n",
       " 'أ',\n",
       " 'ب',\n",
       " 'ت',\n",
       " 'ث',\n",
       " 'ج',\n",
       " 'ح',\n",
       " 'خ',\n",
       " 'د',\n",
       " 'ذ',\n",
       " 'ر',\n",
       " 'ز',\n",
       " 'س',\n",
       " 'ش',\n",
       " 'ص',\n",
       " 'ض',\n",
       " 'ط',\n",
       " 'ظ',\n",
       " 'ع',\n",
       " 'غ',\n",
       " 'ف',\n",
       " 'ق',\n",
       " 'ك',\n",
       " 'ل',\n",
       " 'م',\n",
       " 'ن',\n",
       " 'ه',\n",
       " 'و',\n",
       " 'ي',\n",
       " 'ء',\n",
       " 'ى',\n",
       " 'آ',\n",
       " 'ؤ',\n",
       " 'ئ',\n",
       " 'أ',\n",
       " 'ة',\n",
       " 'ألف',\n",
       " 'باء',\n",
       " 'تاء',\n",
       " 'ثاء',\n",
       " 'جيم',\n",
       " 'حاء',\n",
       " 'خاء',\n",
       " 'دال',\n",
       " 'ذال',\n",
       " 'راء',\n",
       " 'زاي',\n",
       " 'سين',\n",
       " 'شين',\n",
       " 'صاد',\n",
       " 'ضاد',\n",
       " 'طاء',\n",
       " 'ظاء',\n",
       " 'عين',\n",
       " 'غين',\n",
       " 'فاء',\n",
       " 'قاف',\n",
       " 'كاف',\n",
       " 'لام',\n",
       " 'ميم',\n",
       " 'نون',\n",
       " 'هاء',\n",
       " 'واو',\n",
       " 'ياء',\n",
       " 'همزة',\n",
       " 'ي',\n",
       " 'نا',\n",
       " 'ك',\n",
       " 'كن',\n",
       " 'ه',\n",
       " 'إياه',\n",
       " 'إياها',\n",
       " 'إياهما',\n",
       " 'إياهم',\n",
       " 'إياهن',\n",
       " 'إياك',\n",
       " 'إياكما',\n",
       " 'إياكم',\n",
       " 'إياك',\n",
       " 'إياكن',\n",
       " 'إياي',\n",
       " 'إيانا',\n",
       " 'أولالك',\n",
       " 'تانِ',\n",
       " 'تانِك',\n",
       " 'تِه',\n",
       " 'تِي',\n",
       " 'تَيْنِ',\n",
       " 'ثمّ',\n",
       " 'ثمّة',\n",
       " 'ذانِ',\n",
       " 'ذِه',\n",
       " 'ذِي',\n",
       " 'ذَيْنِ',\n",
       " 'هَؤلاء',\n",
       " 'هَاتانِ',\n",
       " 'هَاتِه',\n",
       " 'هَاتِي',\n",
       " 'هَاتَيْنِ',\n",
       " 'هَذا',\n",
       " 'هَذانِ',\n",
       " 'هَذِه',\n",
       " 'هَذِي',\n",
       " 'هَذَيْنِ',\n",
       " 'الألى',\n",
       " 'الألاء',\n",
       " 'أل',\n",
       " 'أنّى',\n",
       " 'أيّ',\n",
       " 'ّأيّان',\n",
       " 'أنّى',\n",
       " 'أيّ',\n",
       " 'ّأيّان',\n",
       " 'ذيت',\n",
       " 'كأيّ',\n",
       " 'كأيّن',\n",
       " 'بضع',\n",
       " 'فلان',\n",
       " 'وا',\n",
       " 'آمينَ',\n",
       " 'آهِ',\n",
       " 'آهٍ',\n",
       " 'آهاً',\n",
       " 'أُفٍّ',\n",
       " 'أُفٍّ',\n",
       " 'أفٍّ',\n",
       " 'أمامك',\n",
       " 'أمامكَ',\n",
       " 'أوّهْ',\n",
       " 'إلَيْكَ',\n",
       " 'إلَيْكَ',\n",
       " 'إليكَ',\n",
       " 'إليكنّ',\n",
       " 'إيهٍ',\n",
       " 'بخٍ',\n",
       " 'بسّ',\n",
       " 'بَسْ',\n",
       " 'بطآن',\n",
       " 'بَلْهَ',\n",
       " 'حاي',\n",
       " 'حَذارِ',\n",
       " 'حيَّ',\n",
       " 'حيَّ',\n",
       " 'دونك',\n",
       " 'رويدك',\n",
       " 'سرعان',\n",
       " 'شتانَ',\n",
       " 'شَتَّانَ',\n",
       " 'صهْ',\n",
       " 'صهٍ',\n",
       " 'طاق',\n",
       " 'طَق',\n",
       " 'عَدَسْ',\n",
       " 'كِخ',\n",
       " 'مكانَك',\n",
       " 'مكانَك',\n",
       " 'مكانَك',\n",
       " 'مكانكم',\n",
       " 'مكانكما',\n",
       " 'مكانكنّ',\n",
       " 'نَخْ',\n",
       " 'هاكَ',\n",
       " 'هَجْ',\n",
       " 'هلم',\n",
       " 'هيّا',\n",
       " 'هَيْهات',\n",
       " 'وا',\n",
       " 'واهاً',\n",
       " 'وراءَك',\n",
       " 'وُشْكَانَ',\n",
       " 'وَيْ',\n",
       " 'يفعلان',\n",
       " 'تفعلان',\n",
       " 'يفعلون',\n",
       " 'تفعلون',\n",
       " 'تفعلين',\n",
       " 'اتخذ',\n",
       " 'ألفى',\n",
       " 'تخذ',\n",
       " 'ترك',\n",
       " 'تعلَّم',\n",
       " 'جعل',\n",
       " 'حجا',\n",
       " 'حبيب',\n",
       " 'خال',\n",
       " 'حسب',\n",
       " 'خال',\n",
       " 'درى',\n",
       " 'رأى',\n",
       " 'زعم',\n",
       " 'صبر',\n",
       " 'ظنَّ',\n",
       " 'عدَّ',\n",
       " 'علم',\n",
       " 'غادر',\n",
       " 'ذهب',\n",
       " 'وجد',\n",
       " 'ورد',\n",
       " 'وهب',\n",
       " 'أسكن',\n",
       " 'أطعم',\n",
       " 'أعطى',\n",
       " 'رزق',\n",
       " 'زود',\n",
       " 'سقى',\n",
       " 'كسا',\n",
       " 'أخبر',\n",
       " 'أرى',\n",
       " 'أعلم',\n",
       " 'أنبأ',\n",
       " 'حدَث',\n",
       " 'خبَّر',\n",
       " 'نبَّا',\n",
       " 'أفعل به',\n",
       " 'ما أفعله',\n",
       " 'بئس',\n",
       " 'ساء',\n",
       " 'طالما',\n",
       " 'قلما',\n",
       " 'لات',\n",
       " 'لكنَّ',\n",
       " 'ءَ',\n",
       " 'أجل',\n",
       " 'إذاً',\n",
       " 'أمّا',\n",
       " 'إمّا',\n",
       " 'إنَّ',\n",
       " 'أنًّ',\n",
       " 'أى',\n",
       " 'إى',\n",
       " 'أيا',\n",
       " 'ب',\n",
       " 'ثمَّ',\n",
       " 'جلل',\n",
       " 'جير',\n",
       " 'رُبَّ',\n",
       " 'س',\n",
       " 'علًّ',\n",
       " 'ف',\n",
       " 'كأنّ',\n",
       " 'كلَّا',\n",
       " 'كى',\n",
       " 'ل',\n",
       " 'لات',\n",
       " 'لعلَّ',\n",
       " 'لكنَّ',\n",
       " 'لكنَّ',\n",
       " 'م',\n",
       " 'نَّ',\n",
       " 'هلّا',\n",
       " 'وا',\n",
       " 'أل',\n",
       " 'إلّا',\n",
       " 'ت',\n",
       " 'ك',\n",
       " 'لمّا',\n",
       " 'ن',\n",
       " 'ه',\n",
       " 'و',\n",
       " 'ا',\n",
       " 'ي',\n",
       " 'تجاه',\n",
       " 'تلقاء',\n",
       " 'جميع',\n",
       " 'حسب',\n",
       " 'سبحان',\n",
       " 'شبه',\n",
       " 'لعمر',\n",
       " 'مثل',\n",
       " 'معاذ',\n",
       " 'أبو',\n",
       " 'أخو',\n",
       " 'حمو',\n",
       " 'فو',\n",
       " 'مئة',\n",
       " 'مئتان',\n",
       " 'ثلاثمئة',\n",
       " 'أربعمئة',\n",
       " 'خمسمئة',\n",
       " 'ستمئة',\n",
       " 'سبعمئة',\n",
       " 'ثمنمئة',\n",
       " 'تسعمئة',\n",
       " 'مائة',\n",
       " 'ثلاثمائة',\n",
       " 'أربعمائة',\n",
       " 'خمسمائة',\n",
       " 'ستمائة',\n",
       " 'سبعمائة',\n",
       " 'ثمانمئة',\n",
       " 'تسعمائة',\n",
       " 'عشرون',\n",
       " 'ثلاثون',\n",
       " 'اربعون',\n",
       " 'خمسون',\n",
       " 'ستون',\n",
       " 'سبعون',\n",
       " 'ثمانون',\n",
       " 'تسعون',\n",
       " 'عشرين',\n",
       " 'ثلاثين',\n",
       " 'اربعين',\n",
       " 'خمسين',\n",
       " 'ستين',\n",
       " 'سبعين',\n",
       " 'ثمانين',\n",
       " 'تسعين',\n",
       " 'بضع',\n",
       " 'نيف',\n",
       " 'أجمع',\n",
       " 'جميع',\n",
       " 'عامة',\n",
       " 'عين',\n",
       " 'نفس',\n",
       " 'لا سيما',\n",
       " 'أصلا',\n",
       " 'أهلا',\n",
       " 'أيضا',\n",
       " 'بؤسا',\n",
       " 'بعدا',\n",
       " 'بغتة',\n",
       " 'تعسا',\n",
       " 'حقا',\n",
       " 'حمدا',\n",
       " 'خلافا',\n",
       " 'خاصة',\n",
       " 'دواليك',\n",
       " 'سحقا',\n",
       " 'سرا',\n",
       " 'سمعا',\n",
       " 'صبرا',\n",
       " 'صدقا',\n",
       " 'صراحة',\n",
       " 'طرا',\n",
       " 'عجبا',\n",
       " 'عيانا',\n",
       " 'غالبا',\n",
       " 'فرادى',\n",
       " 'فضلا',\n",
       " 'قاطبة',\n",
       " 'كثيرا',\n",
       " 'لبيك',\n",
       " 'معاذ',\n",
       " 'أبدا',\n",
       " 'إزاء',\n",
       " 'أصلا',\n",
       " 'الآن',\n",
       " 'أمد',\n",
       " 'أمس',\n",
       " 'آنفا',\n",
       " 'آناء',\n",
       " 'أنّى',\n",
       " 'أول',\n",
       " 'أيّان',\n",
       " 'تارة',\n",
       " 'ثمّ',\n",
       " 'ثمّة',\n",
       " 'حقا',\n",
       " 'صباح',\n",
       " 'مساء',\n",
       " 'ضحوة',\n",
       " 'عوض',\n",
       " 'غدا',\n",
       " 'غداة',\n",
       " 'قطّ',\n",
       " 'كلّما',\n",
       " 'لدن',\n",
       " 'لمّا',\n",
       " 'مرّة',\n",
       " 'قبل',\n",
       " 'خلف',\n",
       " 'أمام',\n",
       " 'فوق',\n",
       " 'تحت',\n",
       " 'يمين',\n",
       " 'شمال',\n",
       " 'ارتدّ',\n",
       " 'استحال',\n",
       " 'أصبح',\n",
       " 'أضحى',\n",
       " 'آض',\n",
       " 'أمسى',\n",
       " 'انقلب',\n",
       " 'بات',\n",
       " 'تبدّل',\n",
       " 'تحوّل',\n",
       " 'حار',\n",
       " 'رجع',\n",
       " 'راح',\n",
       " 'صار',\n",
       " 'ظلّ',\n",
       " 'عاد',\n",
       " 'غدا',\n",
       " 'كان',\n",
       " 'ما انفك',\n",
       " 'ما برح',\n",
       " 'مادام',\n",
       " 'مازال',\n",
       " 'مافتئ',\n",
       " 'ابتدأ',\n",
       " 'أخذ',\n",
       " 'اخلولق',\n",
       " 'أقبل',\n",
       " 'انبرى',\n",
       " 'أنشأ',\n",
       " 'أوشك',\n",
       " 'جعل',\n",
       " 'حرى',\n",
       " 'شرع',\n",
       " 'طفق',\n",
       " 'علق',\n",
       " 'قام',\n",
       " 'كرب',\n",
       " 'كاد',\n",
       " 'هبّ']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('arabic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f42ff21d-29b5-459b-a02f-3fb533a93530",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before appling stemming i am going to removed the stop words beacause they does'n play important role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "28505bb8-2d0d-405b-9673-92491f495823",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5db285ea-1fd9-4618-a4ed-f5ca5a71cb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "07bec9dd-924d-43da-b308-384cb811fc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=nltk.sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "907e9d64-810c-4e00-a0a0-19572530399d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Avul Pakir Jainulabdeen Abdul Kalam (/ˈəbdʊl kəˈlɑːm/ ⓘ; 15 October 1931 – 27 July 2015) was an Indian aerospace scientist and statesman who served as the president of India from 2002 to 2007.',\n",
       " 'Born and raised in a Muslim family in Rameswaram, Tamil Nadu, Kalam studied physics and aerospace engineering.',\n",
       " \"He spent the next four decades as a scientist and science administrator, mainly at the Defence Research and Development Organisation (DRDO) and Indian Space Research Organisation (ISRO) and was intimately involved in India's civilian space programme and military missile development efforts.\",\n",
       " 'He was known as the \"Missile Man of India\" for his work on the development of ballistic missile and launch vehicle technology.',\n",
       " \"He also played a pivotal organisational, technical, and political role in Pokhran-II nuclear tests in 1998, India's second such test after the first test in 1974.\",\n",
       " 'Kalam was elected as the president of India in 2002 with the support of both the ruling Bharatiya Janata Party and the then-opposition Indian National Congress.',\n",
       " 'He was widely referred to as the \"People\\'s President\".',\n",
       " 'He engaged in teaching, writing and public service after his presidency.',\n",
       " \"He was a recipient of several awards, including the Bharat Ratna, India's highest civilian honour.\",\n",
       " 'While delivering a lecture at IIM Shillong, Kalam collapsed and died from an apparent cardiac arrest on 27 July 2015, aged 83.',\n",
       " 'Thousands attended the funeral ceremony held in his hometown of Rameswaram, where he was buried with full state honours.',\n",
       " 'A memorial was inaugurated near his home town in 2017.']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1fbc5a59-5269-4fc5-bc53-9f6abeba9b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7e299da3-b478-4924-8b84-88e506bb6c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Appling stopwords to filter and then appling stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "517e1bd8-d6a7-4b79-9bee-91aa792ed2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Appling stopwords to filter and then appling stemming\n",
    "for  i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    filtered_stemmed_words = [stemmer.stem(word) for word in words if word.lower() not in set(stopwords.words('english'))]\n",
    "    sentences[i] = ' '.join(filtered_stemmed_words)  ## converting all the words into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5c220afc-d4b6-4afe-9e5d-910030cd0f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['avul pakir jainulabdeen abdul kalam ( /ˈəbdʊl kəˈlɑːm/ ⓘ ; 15 octob 1931 – 27 juli 2015 ) indian aerospac scientist statesman serv presid india 2002 2007 .',\n",
       " 'born rais muslim famili rameswaram , tamil nadu , kalam studi physic aerospac engin .',\n",
       " \"spent next four decad scientist scienc administr , mainli defenc research develop organis ( drdo ) indian space research organis ( isro ) intim involv india 's civilian space programm militari missil develop effort .\",\n",
       " \"known `` missil man india '' work develop ballist missil launch vehicl technolog .\",\n",
       " \"also play pivot organis , technic , polit role pokhran-ii nuclear test 1998 , india 's second test first test 1974 .\",\n",
       " 'kalam elect presid india 2002 support rule bharatiya janata parti then-opposit indian nation congress .',\n",
       " \"wide refer `` peopl 's presid '' .\",\n",
       " 'engag teach , write public servic presid .',\n",
       " \"recipi sever award , includ bharat ratna , india 's highest civilian honour .\",\n",
       " 'deliv lectur iim shillong , kalam collaps die appar cardiac arrest 27 juli 2015 , age 83 .',\n",
       " 'thousand attend funer ceremoni held hometown rameswaram , buri full state honour .',\n",
       " 'memori inaugur near home town 2017 .']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "cdcda233-df89-4af9-99b1-dca08789d230",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=\"\"\"I’m Prince Chaudhary, a 3rd-year CSE student focused on data science and algorithms.\n",
    "I optimize scheduling (SJF) and design efficient search strategies.\n",
    "I build image-processing tools in MATLAB and Python on my M3 Pro Mac.\n",
    "I’m passionate about open-source collaboration and machine-learning innovation.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e78a0212-bec0-467e-90d2-de66d89b15ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snowball=SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "562de7f0-b7a4-4b81-9da7-ec47c20a3ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=nltk.sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5767b681-75cc-47b0-a48b-855814a54d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.12/site-packages/IPython/core/formatters.py:370: FormatterWarning: text/html formatter returned invalid type <class 'IPython.core.display.HTML'> (expected <class 'str'>) for object: ['I’m Prince Chaudhary, a 3rd-year CSE student focused on data science and algorithms.', 'I optimize scheduling (SJF) and design efficient search strategies.', 'I build image-processing tools in MATLAB and Python on my M3 Pro Mac.', 'I’m passionate about open-source collaboration and machine-learning innovation.']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['I’m Prince Chaudhary, a 3rd-year CSE student focused on data science and algorithms.',\n",
       " 'I optimize scheduling (SJF) and design efficient search strategies.',\n",
       " 'I build image-processing tools in MATLAB and Python on my M3 Pro Mac.',\n",
       " 'I’m passionate about open-source collaboration and machine-learning innovation.']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "cab5274b-1db6-440b-9469-46c1aa2ff024",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    words=nltk.sent_tokenize(sentences[i])\n",
    "    filtered_stemmed_words=[snowball.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    sentences[i]=''.join(filtered_stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "664d870f-a058-410f-bda4-ad1ecb264a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.12/site-packages/IPython/core/formatters.py:370: FormatterWarning: text/html formatter returned invalid type <class 'IPython.core.display.HTML'> (expected <class 'str'>) for object: [\"i'm prince chaudhary, a 3rd-year cse student focused on data science and algorithms.\", 'i optimize scheduling (sjf) and design efficient search strategies.', 'i build image-processing tools in matlab and python on my m3 pro mac.', \"i'm passionate about open-source collaboration and machine-learning innovation.\"]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"i'm prince chaudhary, a 3rd-year cse student focused on data science and algorithms.\",\n",
       " 'i optimize scheduling (sjf) and design efficient search strategies.',\n",
       " 'i build image-processing tools in matlab and python on my m3 pro mac.',\n",
       " \"i'm passionate about open-source collaboration and machine-learning innovation.\"]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "18061575-48a0-4207-9272-2855428a3e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing same things form Lemmatization\n",
    "corpus=\"\"\"I’m Prince Chaudhary, a 3rd-year CSE student focused on data science and algorithms.\n",
    "I optimize scheduling (SJF) and design efficient search strategies.\n",
    "I build image-processing tools in MATLAB and Python on my M3 Pro Mac.\n",
    "I’m passionate about open-source collaboration and machine-learning innovation.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f88dcb24-609b-432f-95ca-09e00b3b4570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b7f3ff39-dc10-401d-890b-58da58d9cedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=nltk.sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "cd42f72b-bb97-4d3b-80b0-bf52ad7523f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I’m Prince Chaudhary, a 3rd-year CSE student focused on data science and algorithms.',\n",
       " 'I optimize scheduling (SJF) and design efficient search strategies.',\n",
       " 'I build image-processing tools in MATLAB and Python on my M3 Pro Mac.',\n",
       " 'I’m passionate about open-source collaboration and machine-learning innovation.']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "91312c90-29b8-4209-88b5-62c73525bbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    words = word_tokenize(sentences[i])  # Tokenize each sentence into words\n",
    "    # Filter out stopwords and lemmatize the words\n",
    "    filtered_stemmed_words = [lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    sentences[i] = ' '.join(filtered_stemmed_words)  # Join the processed words back into a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7ee1be40-0ce2-45dc-97a0-5ee1d44cf003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.12/site-packages/IPython/core/formatters.py:370: FormatterWarning: text/html formatter returned invalid type <class 'IPython.core.display.HTML'> (expected <class 'str'>) for object: ['I ’ Prince Chaudhary , 3rd-year CSE student focused data science algorithm .', 'I optimize scheduling ( SJF ) design efficient search strategy .', 'I build image-processing tool MATLAB Python M3 Pro Mac .', 'I ’ passionate open-source collaboration machine-learning innovation .']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['I ’ Prince Chaudhary , 3rd-year CSE student focused data science algorithm .',\n",
       " 'I optimize scheduling ( SJF ) design efficient search strategy .',\n",
       " 'I build image-processing tool MATLAB Python M3 Pro Mac .',\n",
       " 'I ’ passionate open-source collaboration machine-learning innovation .']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "83a388fd-f522-4462-a6b5-39c1c15b6909",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parts of speech Tage\n",
    "corpus=\"\"\"I’m Prince Chaudhary, a 3rd-year CSE student focused on data science and algorithms.\n",
    "I optimize scheduling (SJF) and design efficient search strategies.\n",
    "I build image-processing tools in MATLAB and Python on my M3 Pro Mac.\n",
    "I’m passionate about open-source collaboration and machine-learning innovation.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8e9de472-b324-461a-8ae8-aa90cb8ba8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "sentences=nltk.sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7c8f209a-ab6a-435f-ab1a-3d6ffbbafbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/princechaudhary/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/IPython/core/formatters.py:370: FormatterWarning: text/html formatter returned invalid type <class 'IPython.core.display.HTML'> (expected <class 'str'>) for object: True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8994e0fb-b1bc-458c-a838-b4d616e1ecbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I’m Prince Chaudhary, a 3rd-year CSE student focused on data science and algorithms.',\n",
       " 'I optimize scheduling (SJF) and design efficient search strategies.',\n",
       " 'I build image-processing tools in MATLAB and Python on my M3 Pro Mac.',\n",
       " 'I’m passionate about open-source collaboration and machine-learning innovation.']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "28c0a94b-ec76-4a11-8753-ee22e26ee2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP'), ('’', 'VBP'), ('Prince', 'NNP'), ('Chaudhary', 'NNP'), (',', ','), ('3rd-year', 'JJ'), ('CSE', 'NNP'), ('student', 'NN'), ('focused', 'VBD'), ('data', 'NNS'), ('science', 'NN'), ('algorithms', 'NN'), ('.', '.')]\n",
      "[('I', 'PRP'), ('optimize', 'VBP'), ('scheduling', 'VBG'), ('(', '('), ('SJF', 'NNP'), (')', ')'), ('design', 'NN'), ('efficient', 'JJ'), ('search', 'NN'), ('strategies', 'NNS'), ('.', '.')]\n",
      "[('I', 'PRP'), ('build', 'VBP'), ('image-processing', 'JJ'), ('tools', 'NNS'), ('MATLAB', 'NNP'), ('Python', 'NNP'), ('M3', 'NNP'), ('Pro', 'NNP'), ('Mac', 'NNP'), ('.', '.')]\n",
      "[('I', 'PRP'), ('’', 'VBP'), ('passionate', 'JJ'), ('open-source', 'JJ'), ('collaboration', 'NN'), ('machine-learning', 'JJ'), ('innovation', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# We will find the post tag\n",
    "for i in range(len(sentences)):\n",
    "    words = word_tokenize(sentences[i])  \n",
    "    filtered_stemmed_words = [word for word in words if word not in set(stopwords.words('english'))]\n",
    "    pos_tag=nltk.pos_tag(filtered_stemmed_words)\n",
    "    print(pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f45a7b05-cebe-47f1-8d12-6c90375e7877",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name Entity Recoginitions\n",
    "corpus=\"\"\"I’m Prince Chaudhary, a 3rd-year CSE student focused on data science and algorithms.\n",
    "I optimize scheduling (SJF) and design efficient search strategies.\n",
    "I build image-processing tools in MATLAB and Python on my M3 Pro Mac.\n",
    "I’m passionate about open-source collaboration and machine-learning innovation.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af230e85-8c1e-45eb-acb1-283bf4b4bf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "words=nltk.word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e87f986-4690-4ce8-8c42-8fb086038111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " '’',\n",
       " 'm',\n",
       " 'Prince',\n",
       " 'Chaudhary',\n",
       " ',',\n",
       " 'a',\n",
       " '3rd-year',\n",
       " 'CSE',\n",
       " 'student',\n",
       " 'focused',\n",
       " 'on',\n",
       " 'data',\n",
       " 'science',\n",
       " 'and',\n",
       " 'algorithms',\n",
       " '.',\n",
       " 'I',\n",
       " 'optimize',\n",
       " 'scheduling',\n",
       " '(',\n",
       " 'SJF',\n",
       " ')',\n",
       " 'and',\n",
       " 'design',\n",
       " 'efficient',\n",
       " 'search',\n",
       " 'strategies',\n",
       " '.',\n",
       " 'I',\n",
       " 'build',\n",
       " 'image-processing',\n",
       " 'tools',\n",
       " 'in',\n",
       " 'MATLAB',\n",
       " 'and',\n",
       " 'Python',\n",
       " 'on',\n",
       " 'my',\n",
       " 'M3',\n",
       " 'Pro',\n",
       " 'Mac',\n",
       " '.',\n",
       " 'I',\n",
       " '’',\n",
       " 'm',\n",
       " 'passionate',\n",
       " 'about',\n",
       " 'open-source',\n",
       " 'collaboration',\n",
       " 'and',\n",
       " 'machine-learning',\n",
       " 'innovation',\n",
       " '.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6c2c6f7-bda4-4359-b221-851ff93c0f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_ele=nltk.pos_tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25565f57-9b49-40fe-9b54-da2373dd2f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('’', 'VBP'),\n",
       " ('m', 'JJ'),\n",
       " ('Prince', 'NNP'),\n",
       " ('Chaudhary', 'NNP'),\n",
       " (',', ','),\n",
       " ('a', 'DT'),\n",
       " ('3rd-year', 'JJ'),\n",
       " ('CSE', 'NNP'),\n",
       " ('student', 'NN'),\n",
       " ('focused', 'VBD'),\n",
       " ('on', 'IN'),\n",
       " ('data', 'NNS'),\n",
       " ('science', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('algorithms', 'NN'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('optimize', 'VBP'),\n",
       " ('scheduling', 'VBG'),\n",
       " ('(', '('),\n",
       " ('SJF', 'NNP'),\n",
       " (')', ')'),\n",
       " ('and', 'CC'),\n",
       " ('design', 'NN'),\n",
       " ('efficient', 'JJ'),\n",
       " ('search', 'NN'),\n",
       " ('strategies', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('build', 'VBP'),\n",
       " ('image-processing', 'JJ'),\n",
       " ('tools', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('MATLAB', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('Python', 'NNP'),\n",
       " ('on', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('M3', 'NNP'),\n",
       " ('Pro', 'NNP'),\n",
       " ('Mac', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('’', 'VBP'),\n",
       " ('m', 'JJ'),\n",
       " ('passionate', 'NN'),\n",
       " ('about', 'IN'),\n",
       " ('open-source', 'JJ'),\n",
       " ('collaboration', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('machine-learning', 'JJ'),\n",
       " ('innovation', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_ele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dee5582-9c56-4bb2-9f6b-7f90ecf8a993",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]     /Users/princechaudhary/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9caa4aa-6fd6-44f2-9e00-974b442e789a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/princechaudhary/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72ab4261-864e-4a81-b5b8-e14a1d3c6c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.ne_chunk(tag_ele).draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d233555-f6a8-4acf-85e0-dafa65fb7b91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f35bed44-a336-4a0a-95b8-a7eed34266fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word2Vec implemnetatins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "808ecd84-f074-4dcd-9264-3f757a2564ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9da69d2-d713-4d10-a261-af1b55ae9fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec,keyedvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2cfb4fb-9bb2-4666-8e6e-2e1f7df5eba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  gensim.downloader as api\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08a3f004-3ae4-4d3e-a6d2-4f3007aaa98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_king=wv['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ae341c3-b233-42b6-8e7c-947f5363c809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#each word is trained on 300 dimensions\n",
    "len(voc_king)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b331ff39-208d-4c7b-9077-91fb173a28bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cricketing', 0.8372224569320679),\n",
       " ('cricketers', 0.8165745139122009),\n",
       " ('Test_cricket', 0.8094819188117981),\n",
       " ('Twenty##_cricket', 0.8068488240242004),\n",
       " ('Twenty##', 0.7624265551567078),\n",
       " ('Cricket', 0.75413978099823),\n",
       " ('cricketer', 0.7372578382492065),\n",
       " ('twenty##', 0.7316356897354126),\n",
       " ('T##_cricket', 0.7304614186286926),\n",
       " ('West_Indies_cricket', 0.6987985968589783)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar('cricket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf7e7926-0089-40de-946d-8a14c4268e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Corey_Fienhage', 0.5202076435089111),\n",
       " ('coach_Clem_Jodoin', 0.509192705154419),\n",
       " ('Vincent_LoVerde', 0.5069826245307922),\n",
       " ('Pokey_Reddick', 0.4900675415992737),\n",
       " ('goalie_Andrew_Loverock', 0.48931652307510376),\n",
       " ('Alex_Dzielski', 0.4846603274345398),\n",
       " ('Gratchev', 0.4815835654735565),\n",
       " ('Adam_Janosik', 0.4768799841403961),\n",
       " ('Peter_Taglianetti', 0.4763161242008209),\n",
       " ('Mitch_Versteeg', 0.47532919049263)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar('hockey','cricket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7450964d-e11a-4620-a0d0-cc398b30164a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec=wv['king']-wv['man']+wv['women']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1f519f0-e730-4d4d-918d-c31c15ec3514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.33984375,  0.06298828, -0.00994873,  0.3305664 ,  0.10327148,\n",
       "       -0.25854492,  0.19677734, -0.32476807, -0.15917969,  0.45752716,\n",
       "       -0.39208984, -0.22460938,  0.02929688,  0.31982422, -0.0958252 ,\n",
       "       -0.05932617,  0.01855469, -0.03945923,  0.01101685,  0.33984375,\n",
       "        0.10351562,  0.14396667, -0.07641602,  0.06640625, -0.10839844,\n",
       "       -0.1953125 , -0.3564453 , -0.02124023, -0.16503906, -0.16247559,\n",
       "       -0.05519104, -0.1003418 ,  0.01464844,  0.23449707, -0.26611328,\n",
       "       -0.07080078, -0.26904297, -0.00292969, -0.06738281, -0.02050781,\n",
       "        0.04418945, -0.09326172,  0.12304688,  0.10626221,  0.10290527,\n",
       "        0.01660156, -0.10791016, -0.0065918 ,  0.17578125,  0.10028076,\n",
       "        0.22363281, -0.05761719, -0.31743622,  0.3922119 , -0.35498047,\n",
       "       -0.23643494, -0.01074219, -0.01334572, -0.15283203, -0.00793457,\n",
       "        0.08203125,  0.09985352,  0.003479  ,  0.11608887,  0.14550781,\n",
       "       -0.125     , -0.11254883,  0.2548828 , -0.04345703,  0.34985352,\n",
       "       -0.02880859,  0.15966797,  0.07226562,  0.17626953,  0.15979004,\n",
       "       -0.20263672, -0.23864746,  0.3400879 ,  0.17700195,  0.15454102,\n",
       "       -0.20385742,  0.05224609, -0.05224609,  0.3067627 , -0.14892578,\n",
       "       -0.07910156, -0.10107422,  0.06176758,  0.08154297,  0.17700195,\n",
       "        0.04589844, -0.41674805, -0.32019043, -0.16674805,  0.11083984,\n",
       "       -0.02352905,  0.35290527, -0.30004883,  0.25634766, -0.16748047,\n",
       "        0.21386719,  0.12304688, -0.27490234, -0.35009766, -0.4580078 ,\n",
       "        0.38671875, -0.6265869 , -0.13139915,  0.34692383,  0.11553955,\n",
       "        0.42016602,  0.32763672, -0.03381157,  0.08630371,  0.2419281 ,\n",
       "       -0.35412598,  0.19325256, -0.36791992,  0.17056274,  0.1459961 ,\n",
       "       -0.18945312,  0.28393555,  0.01953125, -0.18115234,  0.08374023,\n",
       "       -0.01483154,  0.06591797,  0.21643066, -0.01757812,  0.18481445,\n",
       "        0.01757812,  0.07226562,  0.01220703,  0.4343872 ,  0.2734375 ,\n",
       "        0.20452881,  0.01586914,  0.01391602,  0.33740234, -0.30273438,\n",
       "       -0.00439453, -0.5595703 ,  0.38867188, -0.1373291 ,  0.13574219,\n",
       "       -0.20605469,  0.10742188,  0.02148438, -0.14648438,  0.2142334 ,\n",
       "       -0.06054688,  0.23291016, -0.16430664, -0.4741211 , -0.13745117,\n",
       "       -0.12353516, -0.26293945,  0.03125   ,  0.15332031, -0.08251953,\n",
       "       -0.11865234, -0.10687256,  0.2421875 , -0.11425781, -0.05310059,\n",
       "       -0.30371094, -0.06225586,  0.05029297, -0.07272339,  0.11499023,\n",
       "       -0.2980957 ,  0.09692383,  0.41088867,  0.16601562,  0.3486328 ,\n",
       "       -0.17211914,  0.33325195, -0.19030762,  0.14611816,  0.14916992,\n",
       "       -0.33129883, -0.11791992, -0.39538574, -0.13183594, -0.07034302,\n",
       "        0.03204346,  0.38623047, -0.07495117,  0.15112305,  0.38134766,\n",
       "        0.2423706 , -0.11083984, -0.109375  , -0.08319092, -0.1003418 ,\n",
       "        0.08483887,  0.34039307,  0.11035156,  0.01074219, -0.3815918 ,\n",
       "       -0.1743164 ,  0.14331055,  0.2562256 , -0.2944336 ,  0.00488281,\n",
       "       -0.04443359, -0.06347656,  0.03100586, -0.12084961,  0.41137695,\n",
       "        0.078125  ,  0.34484863, -0.05615234, -0.2998047 ,  0.06054688,\n",
       "        0.17797852, -0.01876068, -0.16064453,  0.09765625, -0.05682373,\n",
       "       -0.2878418 , -0.05664062,  0.19726562, -0.22753906,  0.00268555,\n",
       "       -0.17297363, -0.19726562, -0.15332031,  0.1899414 ,  0.32299805,\n",
       "       -0.18261719, -0.06103516, -0.47460938,  0.1251831 ,  0.08056641,\n",
       "       -0.05444336,  0.17797852,  0.00754547, -0.00805664, -0.18371582,\n",
       "        0.23339844, -0.39074707,  0.18608856,  0.12158203,  0.2767334 ,\n",
       "       -0.06054688, -0.28857422,  0.3359375 , -0.02954102, -0.12329102,\n",
       "        0.09594727,  0.1965332 ,  0.15771484, -0.015625  ,  0.20019531,\n",
       "       -0.07763672, -0.30419922, -0.21777344,  0.06689453,  0.11193848,\n",
       "       -0.03125   ,  0.17773438, -0.05078125,  0.15014648, -0.19580078,\n",
       "       -0.2319336 , -0.04980469,  0.16308594,  0.4963379 ,  0.64746094,\n",
       "        0.03808594,  0.5743408 , -0.1274414 ,  0.16711426,  0.12188721,\n",
       "       -0.43432617, -0.3585205 , -0.12646484, -0.04003906,  0.39794922,\n",
       "        0.25683594, -0.45654297,  0.3178711 , -0.24658203,  0.16040039,\n",
       "       -0.11010742, -0.14331055, -0.0291748 ,  0.02893066, -0.03295898,\n",
       "       -0.05691528, -0.11279297, -0.18359375, -0.4482422 , -0.00830078,\n",
       "       -0.12371826, -0.02783203,  0.26367188,  0.27148438,  0.28808594],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "449e7e9a-4f89-48f6-ba10-1e46d2d6baa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('king', 0.6478992104530334),\n",
       " ('queen', 0.535493791103363),\n",
       " ('women', 0.52336585521698),\n",
       " ('kings', 0.5162314772605896),\n",
       " ('queens', 0.4995364844799042),\n",
       " ('kumaris', 0.492384672164917),\n",
       " ('princes', 0.46233269572257996),\n",
       " ('monarch', 0.4528028964996338),\n",
       " ('monarchy', 0.429317444562912),\n",
       " ('kings_princes', 0.42342400550842285)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1255d7c1-8410-4083-b03b-6da7959dcbdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
